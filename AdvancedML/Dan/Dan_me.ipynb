{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb937d9-7c2d-474b-b3ce-3bbcf8f1641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c57e7b-5a4c-40b9-9476-f69d9711a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "OL_phase = np.load('../data/OutLoop/OL_Phase.npy')\n",
    "OL_amp = np.load('../data/OutLoop/OL_Magnitude.npy')\n",
    "OL_e = np.load('../data/OutLoop/OL_Energy.npy')\n",
    "IL_phase = np.load('../data/OutLoop/IL_Phase.npy')\n",
    "IL_amp = np.load('../data/OutLoop/IL_Magnitude.npy')\n",
    "IL_e = np.load('../data/OutLoop/IL_energy.npy')\n",
    "Laser_amp = np.load('../data/OutLoop/Laser_Amp.npy')\n",
    "Laser_phase = np.load('../data/OutLoop/Laser_Phs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18795371-d116-4d13-b37c-dd2962da43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.load('../data/OutLoop/CameraFit.npy')\n",
    "#y2 = np.load('../data/OutLoop/CameraProj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5dc94d-8446-4b30-958f-77f7b21e6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.concatenate((OL_phase, OL_amp,OL_e,IL_phase,IL_amp,IL_e,Laser_phase,Laser_amp), axis=0)\n",
    "x = np.concatenate((OL_phase,OL_e,Laser_amp), axis=0)\n",
    "X = x.reshape([y1.shape[0],-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe1753-f5fe-42a0-99a4-6e85b71b9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = y1.reshape([y1.shape[0],-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d01856-257d-4918-8e7c-cf51af3cc677",
   "metadata": {},
   "source": [
    "## normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe0669f-f780-4302-9290-5a7714c236e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_X = np.mean(X, axis=0)\n",
    "sigma_X = np.std(X, axis=0)\n",
    "_X = (X - mu_X)/sigma_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6afb3-62b0-4ec1-b826-155c1385a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_Y = np.mean(Y, axis=0)\n",
    "sigma_Y = np.std(Y, axis=0)\n",
    "_Y = (Y - mu_Y) / sigma_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d33863-530a-4c8d-8cb1-3faff659995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_X.shape,_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525a3a1-21a2-43a0-b2cb-a3a5d36d1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rms focus distance',np.format_float_scientific(sigma_Y, precision=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3ee92-87d4-421d-b5d2-18dc7147c388",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make pytorch datasets based on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac02e8-036e-4d88-a512-2dabf7f0590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8144e73e-1a91-49cd-ba1d-57c1fb016b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhasedegDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, Y):\n",
    "        self.len = X.shape[0]\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.Y = torch.from_numpy(Y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60996fbc-50da-40c2-86d1-c6e3fb0672b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_deg_dataset = PhasedegDataset(_X, _Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf60623-3564-469e-98fc-710a8b6b431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(phase_deg_dataset)\n",
    "\n",
    "vali_num = int(0.1 * total_num)\n",
    "\n",
    "train_num = total_num - vali_num\n",
    "train_num, vali_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c5031-1b04-4b41-a412-d4dbc1262aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, vali_dataset = random_split(phase_deg_dataset, [train_num, vali_num])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7778d5a-d535-43e2-b87e-d1f1673d0e42",
   "metadata": {},
   "source": [
    "### make a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872ce00-8103-4098-9f76-496d3a67c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocusModel(nn.Module):\n",
    "    # Phase to image model\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FocusModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(_X.shape[1], 30)\n",
    "        self.fc2 = nn.Linear(30, 20)\n",
    "        self.fc3 = nn.Linear(20, _Y.shape[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab375a0-03d7-4667-a3c7-58ebf19c2d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FocusModel()\n",
    "net = net.float()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ad5c4-1c18-485d-a1b8-af343234dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurals_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(neurals_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66125f8-d51b-447c-8344-e93ddabb6592",
   "metadata": {},
   "source": [
    "### loss function and optimazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b6b5a-0e4e-4336-9eee-0f81a03e2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963b60e-90a1-4f8f-b509-0e9e64a3a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a182f9-a17a-4a80-a2ba-1c58dee3275b",
   "metadata": {},
   "source": [
    "### train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7250ff-f463-46a4-83db-58ab65937f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, batch_size, patience, n_epochs):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = [] \n",
    "        \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        model.train() \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, targets = data[0].float().to(device), data[1].float().to(device)        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.sqrt(criterion(outputs, targets))*sigma_Y[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        model.eval() \n",
    "        for data in valid_loader:\n",
    "            inputs, targets = data[0].float().to(device), data[1].float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.sqrt(criterion(outputs, targets))*sigma_Y[0]\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        with open('train_loss.npy', 'wb') as f:\n",
    "            np.save(f, avg_train_losses)\n",
    "        with open('valid_loss.npy', 'wb') as f:\n",
    "            np.save(f, avg_valid_losses)\n",
    "        \n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e720692d-a9f6-448a-b20f-44317ae5f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "n_epochs = 1000\n",
    "patience = 15\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=vali_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model, train_loss, valid_loss = train_model(net, batch_size, patience, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926f920-e1bf-402b-8ef3-342a038a1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = np.load('train_loss.npy')\n",
    "valid_losses = np.load('valid_loss.npy')\n",
    "\n",
    "fs = 24\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(train_losses,label = 'train loss')\n",
    "ax.plot(valid_losses, label = 'valid loss')\n",
    "\n",
    "ax.set_xlabel('training epoch',fontsize = fs)\n",
    "ax.set_ylabel('RMS error [meter]',fontsize = fs)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=fs-2 )\n",
    "plt.yticks(fontsize=fs-2 )\n",
    "plt.legend(fontsize = fs,loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec3caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
